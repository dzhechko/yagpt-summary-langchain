{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2aca8168-62ec-4bba-93f0-73da08cd1920",
   "metadata": {
    "id": "2aca8168-62ec-4bba-93f0-73da08cd1920"
   },
   "source": [
    "---\n",
    "Тема: Суммаризация и краткий перессказ\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13f702",
   "metadata": {
    "id": "cf13f702"
   },
   "source": [
    "## Сценарий\n",
    "\n",
    "Предположим, у вас есть набор документов (PDF-файлы, концептуальные страницы, вопросы клиентов и т.д.), и вы хотите обобщить содержание.\n",
    "\n",
    "LLM - отличный инструмент для этого, учитывая их умение понимать и синтезировать текст.\n",
    "\n",
    "В этом пошаговом руководстве мы рассмотрим, как выполнить обобщение документов с помощью LLM. Предположим, у вас есть набор документов (PDF-файлы, вопросы клиентов и т.д.), и вы хотите обобщить содержание.\n",
    "\n",
    "LLM - отличный инструмент для этого, учитывая их умение понимать и синтезировать текст.\n",
    "\n",
    "В этом пошаговом руководстве мы рассмотрим, как выполнить обобщение документов с помощью LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e233997",
   "metadata": {
    "id": "8e233997"
   },
   "source": [
    "![Image description](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/summarization_use_case_1.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4715b4ff",
   "metadata": {
    "id": "4715b4ff",
    "tags": []
   },
   "source": [
    "## Обзор\n",
    "\n",
    "Центральным вопросом при создании модуля краткого перессказа является то, как передать ваши документы в контекстное окно LLM. Двумя распространенными подходами для этого являются:\n",
    "\n",
    "1. `Stuff`: Просто \"запихните\" все ваши документы в один промпт. Это самый простой подход (вот [здесь](/docs/modules/chains#lcel-chains) дополнительная информация по `create_stuff_documents_chain` конструктору, который используется для этого метода).\n",
    "\n",
    "2. `Map-reduce`: Обобщите каждый документ отдельно на шаге \"map\" и затем преобразуйте в итоговое резюме на шаге \"reduce\" (вот [здесь](/docs/modules/chains#legacy-chains) можно найти дополнительную информацию по `MapReduceDocumentsChain`, который используется в этом методе)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ec66bc",
   "metadata": {
    "id": "08ec66bc"
   },
   "source": [
    "![Image description](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/summarization_use_case_2.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea785ac",
   "metadata": {
    "id": "bea785ac"
   },
   "source": [
    "## Быстрый старт\n",
    "\n",
    "Для краткости отметим, что любой конвейер может быть обернут в один объект: `load_summarize_chain`.\n",
    "\n",
    "Предположим, мы хотим подвести итог записи в блоге. Мы можем создать это с помощью нескольких строк кода.\n",
    "\n",
    "Сначала задаем переменные окружения и устанавливаем пакеты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578d6a90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T12:57:31.368015Z",
     "iopub.status.busy": "2024-03-14T12:57:31.367279Z",
     "iopub.status.idle": "2024-03-14T12:58:09.827117Z",
     "shell.execute_reply": "2024-03-14T12:58:09.826215Z",
     "shell.execute_reply.started": "2024-03-14T12:57:31.367968Z"
    },
    "id": "578d6a90",
    "outputId": "51bb4525-e80b-4ba6-a750-2081965a28c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script uvicorn is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script humanfriendly is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script watchfiles is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script coloredlogs is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script pyproject-build is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts opentelemetry-bootstrap and opentelemetry-instrument are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script onnxruntime_test is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script chroma is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.24.0 requires pympler<2,>=0.9, which is not installed.\n",
      "argilla 1.16.0 requires numpy<1.24.0, but you have numpy 1.25.1 which is incompatible.\n",
      "argilla 1.16.0 requires typer<0.8.0,>=0.6.0, but you have typer 0.9.0 which is incompatible.\n",
      "langchain-openai 0.0.8 requires langchain-core<0.2.0,>=0.1.27, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain-text-splitters 0.0.1 requires langchain-core<0.2.0,>=0.1.28, but you have langchain-core 0.1.23 which is incompatible.\n",
      "litellm 1.15.1 requires certifi<2024.0.0,>=2023.7.22, but you have certifi 2024.2.2 which is incompatible.\n",
      "streamlit 1.24.0 requires pillow<10,>=6.2.0, but you have pillow 10.2.0 which is incompatible.\n",
      "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 13.0.0 which is incompatible.\n",
      "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  yandexcloud==0.255.0 chromadb langchain==0.1.4\n",
    "\n",
    "# Определите переменные SA_ID, KEY_ID, YC_FOLDER_ID или загрузите их из .env файла\n",
    "# import dotenv\n",
    "\n",
    "# dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36138740",
   "metadata": {
    "id": "36138740"
   },
   "source": [
    "Можно использовать `chain_type=\"stuff\"\n",
    "\n",
    "А также `chain_type=\"map_reduce\"` или `chain_type=\"refine\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b1ec58-5f46-402a-bd71-91bfe57eb20d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T13:34:49.193825Z",
     "iopub.status.busy": "2024-03-14T13:34:49.193031Z",
     "iopub.status.idle": "2024-03-14T13:34:49.204094Z",
     "shell.execute_reply": "2024-03-14T13:34:49.203446Z",
     "shell.execute_reply.started": "2024-03-14T13:34:49.193782Z"
    }
   },
   "source": [
    "##### Получаем IAM-токен для работы с YandexGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6760c68f-9172-4281-abf5-6dc8ba74ac2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T13:39:43.876517Z",
     "iopub.status.busy": "2024-03-14T13:39:43.875751Z",
     "iopub.status.idle": "2024-03-14T13:39:44.123628Z",
     "shell.execute_reply": "2024-03-14T13:39:44.122903Z",
     "shell.execute_reply.started": "2024-03-14T13:39:43.876487Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import jwt\n",
    "import requests\n",
    "import os\n",
    "service_account_id = os.environ[\"SA_ID\"]\n",
    "key_id = os.environ[\"KEY_ID\"]\n",
    "folder_id = os.environ[\"YC_FOLDER_ID\"]\n",
    "private_key = \"-----BEGIN PRIVATE KEY-----ЗДЕСЬ УКАЖИТЕ ВАШ ПРИВАТНЫЙ КЛЮЧ-----END PRIVATE KEY-----\\n\"\n",
    "# Получаем IAM-токен\n",
    "now = int(time.time())\n",
    "payload = {\n",
    "        'aud': 'https://iam.api.cloud.yandex.net/iam/v1/tokens',\n",
    "        'iss': service_account_id,\n",
    "        'iat': now,\n",
    "        'exp': now + 360}\n",
    "# Формирование JWT\n",
    "encoded_token = jwt.encode(\n",
    "    payload,\n",
    "    private_key,\n",
    "    algorithm='PS256',\n",
    "    headers={'kid': key_id})\n",
    "url = 'https://iam.api.cloud.yandex.net/iam/v1/tokens'\n",
    "x = requests.post(url,  \n",
    "                  headers={'Content-Type': 'application/json'},\n",
    "                  json = {'jwt': encoded_token}).json()\n",
    "token = x['iamToken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fd271681",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:41:47.677433Z",
     "iopub.status.busy": "2024-03-14T15:41:47.676533Z",
     "iopub.status.idle": "2024-03-14T15:41:52.101348Z",
     "shell.execute_reply": "2024-03-14T15:41:52.100447Z",
     "shell.execute_reply.started": "2024-03-14T15:41:47.677386Z"
    },
    "id": "fd271681",
    "outputId": "bcd44875-2454-4b65-b61d-80a1428ca86d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Yandex Cloud предоставляет меры безопасности для своих пользователей.\n",
      "- Компания использует систему управления информационной безопасностью и разделяет ответственность за обеспечение безопасности.\n",
      "- Yandex Cloud обеспечивает защиту от атак на цепочки поставок и защиту данных пользователей.\n",
      "- В компании проводятся внутренние и внешние аудиты для проверки безопасности.\n",
      "- Уведомления клиентам о инцидентах предоставляются в соответствии с договором.\n",
      "- Управление персоналом Yandex Cloud включает проверку кандидатов на работу и обучение сотрудников.\n",
      "- Непрерывность бизнеса обеспечивается через систему управления непрерывностью и резервное копирование данных.\n",
      "- Безопасность инфраструктуры облачной платформы обеспечивается через разделение ресурсов и контроль доступа.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.chat_models import ChatYandexGPT\n",
    "# url = \"https://cloud.yandex.ru/ru/docs/yandexgpt/concepts/\"\n",
    "url = \"https://cloud.yandex.ru/ru/docs/security/standarts\"\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "\n",
    "# model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt-lite/latest\"\n",
    "# model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt/latest\"\n",
    "model_uri = \"gpt://\"+str(folder_id)+\"/summarization/latest\" #модель, специально обученная для решения задачи краткого перессказа\n",
    "llm = ChatYandexGPT(iam_token = token, model_uri=model_uri, temperature = 0)\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "print(chain.run(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b36e1",
   "metadata": {
    "id": "615b36e1"
   },
   "source": [
    "## Вариант 1. Stuff\n",
    "\n",
    "Когда мы используем `load_summarize_chain` с `chain_type=\"stuff\"`, мы применяем [StuffDocumentsChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.StuffDocumentsChain.html#langchain.chains.combine_documents.stuff.StuffDocumentsChain).\n",
    "\n",
    "Цепочка возьмет список документов, вставит их все в приглашение и передаст это приглашение LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef45585d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:17:15.471130Z",
     "iopub.status.busy": "2024-03-14T15:17:15.470450Z",
     "iopub.status.idle": "2024-03-14T15:17:18.380869Z",
     "shell.execute_reply": "2024-03-14T15:17:18.380260Z",
     "shell.execute_reply.started": "2024-03-14T15:17:15.471100Z"
    },
    "id": "ef45585d",
    "outputId": "8f6b5419-7c82-4b1d-ca26-a8c0f5b0e0e7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- YandexGPT API - это сервис, который позволяет использовать генеративные нейросети для создания текстового контента\n",
      "- YandexGPT API является частью Yandex Foundation Models и объединяет несколько больших генеративных нейронных сетей\n",
      "- Нейросеть YandexGTPT решает различные задачи, такие как создание описания товаров, статей, новостей, информационных рассылок и постов для блога\n",
      "- Качество ответа зависит от точности передаваемой инструкции\n",
      "- Сервис активно развивается и функциональность дополняется\n",
      "- В YandexGPT API есть два режима работы: синхронный и асинхронный\n",
      "- Оба режима не могут обрабатывать бесконечное количество информации, максимальное количество токенов составляет 8 000\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Определим промпт\n",
    "prompt_template = \"\"\"Напишите краткое изложение следующего:\n",
    "\"{text}\"\n",
    "Краткое изложение:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Определим LLM цепочку\n",
    "# model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt-lite/latest\"\n",
    "# model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt/latest\"\n",
    "model_uri = \"gpt://\"+str(folder_id)+\"/summarization/latest\" #модель, специально обученная для решения задачи краткого перессказа\n",
    "llm = ChatYandexGPT(iam_token = token, model_uri=model_uri, temperature = 0)\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Определим StuffDocumentsChain\n",
    "stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"text\")\n",
    "\n",
    "docs = loader.load()\n",
    "print(stuff_chain.run(docs))\n",
    "# print(stuff_chain.invoke(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e4a43",
   "metadata": {
    "id": "4e4e4a43"
   },
   "source": [
    "Мы можем видеть, что мы воспроизводим более ранний результат, используя `load_summarize_chain`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6cabee",
   "metadata": {
    "id": "ad6cabee"
   },
   "source": [
    "## Вариант 2. Map-Reduce\n",
    "\n",
    "Давайте разберемся с подходом map reduce. Для этого мы сначала сопоставим каждый документ с отдельным перессказом, используя `LLMChain`. После этого используем `ReduceDocumentsChain` чтоб объединить эти пересказы в общую краткую сводку.\n",
    "\n",
    "Сначала мы указываем цепочку LLMChain, которую будем использовать для сопоставления каждого документа с отдельным кратким пересказом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1e6773c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:26:55.251743Z",
     "iopub.status.busy": "2024-03-14T15:26:55.250953Z",
     "iopub.status.idle": "2024-03-14T15:26:55.290926Z",
     "shell.execute_reply": "2024-03-14T15:26:55.289873Z",
     "shell.execute_reply.started": "2024-03-14T15:26:55.251697Z"
    },
    "id": "a1e6773c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt-lite/latest\"\n",
    "# model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt/latest\"\n",
    "model_uri = \"gpt://\"+str(folder_id)+\"/summarization/latest\" #модель, специально обученная для решения задачи краткого перессказа\n",
    "llm = ChatYandexGPT(iam_token = token, model_uri=model_uri, temperature = 0)\n",
    "\n",
    "# Map\n",
    "map_template = \"\"\"Ниже приведен набор документов\n",
    "{docs}\n",
    "Основываясь на этом списке документов, пожалуйста, определи основные темы\n",
    "Полезный ответ:\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ce8ce-919d-4ded-bbd5-a53a8a30bc66",
   "metadata": {
    "id": "272ce8ce-919d-4ded-bbd5-a53a8a30bc66"
   },
   "source": [
    "Можем также использовать Prompt Hub для хранения и извлечения промптов.\n",
    "\n",
    "Это будет работать с вашим [LangSmith API key](https://docs.smith.langchain.com/).\n",
    "\n",
    "Например, пример map промпта [здесь](https://smith.langchain.com/hub/rlm/map-prompt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce48b805-d98b-4e0f-8b9e-3b3e72cad3d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T14:47:20.995161Z",
     "iopub.status.busy": "2024-03-14T14:47:20.994371Z",
     "iopub.status.idle": "2024-03-14T14:47:21.773757Z",
     "shell.execute_reply": "2024-03-14T14:47:21.773027Z",
     "shell.execute_reply.started": "2024-03-14T14:47:20.995128Z"
    },
    "id": "ce48b805-d98b-4e0f-8b9e-3b3e72cad3d3"
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "map_prompt = hub.pull(\"rlm/map-prompt\")\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3c331",
   "metadata": {
    "id": "bee3c331"
   },
   "source": [
    "`ReduceDocumentsChain` обрабатывает получение результатов сопоставления документов и сведение их в единый вывод. Он оборачивает общий `CombineDocumentsChain` (как и `StuffDocumentsChain`) но добавляет возможность сворачивать документы перед передачей их в `CombineDocumentsChain` если их совокупный размер превышает `token_max`. В этом примере мы действительно можем сократить цепочку для объединения всех документов, чтобы также свернуть наши документы.\n",
    "\n",
    "Таким образом, если совокупное количество токенов в наших сопоставленных документах превысит 4000 токенов, то мы будем рекурсивно передавать документы пакетами по < 4000 токенов в наш`StuffDocumentsChain` для создания групповых сводок.И как только эти групповые сводки в совокупности составят менее 4000 токенов, мы передадим их все в последний раз в `StuffDocumentsChain` чтобы создать итоговую сводку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a718890-99ab-439a-8f79-b9ae9c58ad24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:18:56.705786Z",
     "iopub.status.busy": "2024-03-14T15:18:56.705141Z",
     "iopub.status.idle": "2024-03-14T15:18:56.720475Z",
     "shell.execute_reply": "2024-03-14T15:18:56.719786Z",
     "shell.execute_reply.started": "2024-03-14T15:18:56.705758Z"
    },
    "id": "6a718890-99ab-439a-8f79-b9ae9c58ad24",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reduce\n",
    "reduce_template = \"\"\"Ниже приведен набор кратких выжимок из документов:\n",
    "{docs}\n",
    "Возьми их и сформируй из них окончательное, сводное резюме по основным темам.\n",
    "Полезный ответ:\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f189184a-673e-4530-8a6b-57b091045d87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T14:53:32.220579Z",
     "iopub.status.busy": "2024-03-14T14:53:32.219773Z",
     "iopub.status.idle": "2024-03-14T14:53:32.880028Z",
     "shell.execute_reply": "2024-03-14T14:53:32.879322Z",
     "shell.execute_reply.started": "2024-03-14T14:53:32.220538Z"
    },
    "id": "f189184a-673e-4530-8a6b-57b091045d87"
   },
   "outputs": [],
   "source": [
    "# Note we can also get this from the prompt hub, as noted above\n",
    "reduce_prompt = hub.pull(\"rlm/map-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9d1da97-d590-4a96-82b2-8002d27fd7f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T14:53:34.010145Z",
     "iopub.status.busy": "2024-03-14T14:53:34.009496Z",
     "iopub.status.idle": "2024-03-14T14:53:34.020881Z",
     "shell.execute_reply": "2024-03-14T14:53:34.020300Z",
     "shell.execute_reply.started": "2024-03-14T14:53:34.010111Z"
    },
    "id": "c9d1da97-d590-4a96-82b2-8002d27fd7f6",
    "outputId": "907adf33-fd89-4064-e80f-8acaa1d907c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['docs'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['docs'], template='The following is a set of documents:\\n{docs}\\nBased on this list of docs, please identify the main themes \\nHelpful Answer:'))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1edb1b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:19:52.827038Z",
     "iopub.status.busy": "2024-03-14T15:19:52.826384Z",
     "iopub.status.idle": "2024-03-14T15:19:52.852902Z",
     "shell.execute_reply": "2024-03-14T15:19:52.852306Z",
     "shell.execute_reply.started": "2024-03-14T15:19:52.827000Z"
    },
    "id": "1edb1b0d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run chain\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "# Берет список документов, объединяет их в одну строку и передает в LLMChain\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
    ")\n",
    "\n",
    "# Объединяет и итеративно сокращает сопоставленные документы\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # Это конечная цепочка, которая вызывается.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # Если размер документов выходит за рамки контекста для `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # Максимальное количество токенов для группировки документов.\n",
    "    token_max=4000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5ae1a",
   "metadata": {
    "id": "fdb5ae1a"
   },
   "source": [
    "Объединяет нашу map and reduce цепочку в одну:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22f1cdc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:27:07.165418Z",
     "iopub.status.busy": "2024-03-14T15:27:07.164665Z",
     "iopub.status.idle": "2024-03-14T15:27:07.187887Z",
     "shell.execute_reply": "2024-03-14T15:27:07.187012Z",
     "shell.execute_reply.started": "2024-03-14T15:27:07.165374Z"
    },
    "id": "22f1cdc2",
    "outputId": "0945c0ce-3f1b-4b7b-ba2f-2bc045c9dae3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Объединение документов путем сопоставления цепочки над ними, а затем объединение результатов\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # Map chain\n",
    "    llm_chain=map_chain,\n",
    "    # Reduce chain\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # Имя переменной в llm_chain в которую помещаются документы\n",
    "    document_variable_name=\"docs\",\n",
    "    # Возвращает результаты выполнения шагов сопоставления в выходных данных\n",
    "    return_intermediate_steps=False,\n",
    ")\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 0\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE, \n",
    "    chunk_overlap=CHUNK_OVERLAP)\n",
    "# text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "#     chunk_size=1000, chunk_overlap=0\n",
    "# )\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7afb8c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:27:27.907802Z",
     "iopub.status.busy": "2024-03-14T15:27:27.907041Z",
     "iopub.status.idle": "2024-03-14T15:27:39.988261Z",
     "shell.execute_reply": "2024-03-14T15:27:39.987315Z",
     "shell.execute_reply.started": "2024-03-14T15:27:27.907755Z"
    },
    "id": "c7afb8c3",
    "outputId": "9a9f383d-a12a-4136-d821-4801c98ce222",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_community.chat_models.yandex.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised _MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
      "\tstatus = StatusCode.RESOURCE_EXHAUSTED\n",
      "\tdetails = \"ai.textGenerationCompletionSessionsCount.count gauge quota limit exceed: allowed 1 requests\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:158.160.54.160:443 {created_time:\"2024-03-14T15:27:33.865290778+00:00\", grpc_status:8, grpc_message:\"ai.textGenerationCompletionSessionsCount.count gauge quota limit exceed: allowed 1 requests\"}\"\n",
      ">.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- YandexGPT API предоставляет доступ к генеративным нейронным сетям.\n",
      "- Компания Yandex Cloud предоставляет YandexGPT API на стадии Preview.  \n",
      "- Яндекс Облако создало YandexGPT API, объединяющее несколько генеративных нейронных моделей.  \n",
      " - Цель Yandex Foundation - помощь пользователям в использовании генеративных нейросетей для бизнес-задач.  \n",
      "Нейросеть YandexGTP решает задачи текстового контента: описание товаров, новостей и т.д.  \n",
      "Качество ответа зависит от точной инструкции.  \n",
      "Сервис активно развивается, функциональность расширяется.  \n",
      "Примеры инструкций и запросов можно найти в Библиотеке Promt YandexGPT API  \n",
      "YandexGPT API работает в синхронном и асинхронном режимах.  \n",
      "Синхронный режим используется для чат-ботов, асинхронный для задач без немедленного ответа.  \n",
      "Максимальное количество токенов для обоих режимов - 8000\n"
     ]
    }
   ],
   "source": [
    "print(map_reduce_chain.run(split_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62c21cf",
   "metadata": {
    "id": "e62c21cf"
   },
   "source": [
    "### Дополнительная информация\n",
    "\n",
    "**Что можно \"подкрутить\"**\n",
    "\n",
    "* Как показано выше, вы можете настроить LLM и промпты для этапов map and reduce.\n",
    "\n",
    "**Реальный сценарий**\n",
    "\n",
    "* См. [этот блог-пост](https://blog.langchain.dev/llms-to-improve-documentation/) тематическое исследование по анализу взаимодействий с пользователями (вопросы по LangChain документации)\n",
    "  \n",
    "* Связанный с этим блог-пост [репозиторий](https://github.com/mendableai/QA_clustering) также представляет кластеризацию как средство для суммаризации (краткого перессказа).\n",
    "* Это открывает третий путь помимо `stuff` или `map-reduce` подходов, который имеет смысл рассматривать\n",
    "\n",
    "![описание схемы](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/summarization_use_case_3.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ff365",
   "metadata": {
    "id": "f08ff365"
   },
   "source": [
    "## Вариант 3. Refine\n",
    "\n",
    "[RefineDocumentsChain](/docs/modules/chains#legacy-chains) похож на map-reduce:\n",
    "\n",
    "> The refine documents создает ответ, перебирая входные документы и итеративно обновляя свой ответ. Для каждого документа он передает все входные данные, не относящиеся к документу, текущий документ и последний промежуточный ответ в цепочку LLM, чтобы получить новый ответ.\n",
    "\n",
    "Это можно легко запустить с помощью `chain_type=\"refine\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de1dc10e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:28:13.846893Z",
     "iopub.status.busy": "2024-03-14T15:28:13.845986Z",
     "iopub.status.idle": "2024-03-14T15:28:24.364845Z",
     "shell.execute_reply": "2024-03-14T15:28:24.363996Z",
     "shell.execute_reply.started": "2024-03-14T15:28:13.846844Z"
    },
    "id": "de1dc10e",
    "outputId": "946b074a-08ae-40ef-f06a-826361fe30e8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_community.chat_models.yandex.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised _MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
      "\tstatus = StatusCode.RESOURCE_EXHAUSTED\n",
      "\tdetails = \"ai.textGenerationCompletionSessionsCount.count gauge quota limit exceed: allowed 1 requests\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:158.160.54.160:443 {created_time:\"2024-03-14T15:28:15.987151894+00:00\", grpc_status:8, grpc_message:\"ai.textGenerationCompletionSessionsCount.count gauge quota limit exceed: allowed 1 requests\"}\"\n",
      ">.\n",
      "Retrying langchain_community.chat_models.yandex.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised _MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
      "\tstatus = StatusCode.RESOURCE_EXHAUSTED\n",
      "\tdetails = \"ai.textGenerationCompletionSessionsCount.count gauge quota limit exceed: allowed 1 requests\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:158.160.54.160:443 {created_time:\"2024-03-14T15:28:20.979942017+00:00\", grpc_status:8, grpc_message:\"ai.textGenerationCompletionSessionsCount.count gauge quota limit exceed: allowed 1 requests\"}\"\n",
      ">.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Яндекс GPT - сервис Yandex Cloud для генерации текстового контента на основе инструкций.  \n",
      "- Качество ответов зависит от точности и ясности инструкций.  \n",
      " - Сервис активно развивается и дополняется новыми возможностями.  \n",
      "Примеры инструкций и задач можно найти в библиотеке Промтов.  \n",
      "Есть два режима работы с сервисом: Промт и Чат.  \n",
      "В Промт-режиме пользователь отправляет инструкции и запросы, получая ответы.  \n",
      " В режиме Чат пользователь общается с моделью и уточняет задания, сохраняя контекст предыдущих сообщений.  \n",
      "Сообщения можно отправлять через обновленное API.\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "print(chain.run(split_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b46f44d",
   "metadata": {
    "id": "5b46f44d"
   },
   "source": [
    "Также возможно ввести запрос и вернуть промежуточные шаги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f86c8072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:30:43.567610Z",
     "iopub.status.busy": "2024-03-14T15:30:43.566853Z",
     "iopub.status.idle": "2024-03-14T15:30:52.481675Z",
     "shell.execute_reply": "2024-03-14T15:30:52.480894Z",
     "shell.execute_reply.started": "2024-03-14T15:30:43.567565Z"
    },
    "id": "f86c8072",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Напишите краткое изложение следующего:\n",
    "{text}\n",
    "КРАТКОЕ ИЗЛОЖЕНИЕ:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "refine_template = (\n",
    "    \"Твоя задача подготовить окончательное краткое содержание\\n\"\n",
    "    \"Мы предоставили существующую краткую сводку до определенного момента: {existing_answer}\\n\"\n",
    "    \"У нас есть возможность доработать существующую краткую сводку\"\n",
    "    \"(только если требуется) с еще некоторым контекстом ниже.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Учитывая новый контекст, доработайте первоначальную краткую сводку на русском языке\"\n",
    "    \"Если контекст бесполезен, верните исходную краткую сводку.\"\n",
    ")\n",
    "refine_prompt = PromptTemplate.from_template(refine_template)\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    question_prompt=prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    input_key=\"input_documents\",\n",
    "    output_key=\"output_text\",\n",
    ")\n",
    "result = chain({\"input_documents\": split_docs}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9600b67-79d4-4f85-aba2-9fe81fa29f49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:31:00.751033Z",
     "iopub.status.busy": "2024-03-14T15:31:00.750282Z",
     "iopub.status.idle": "2024-03-14T15:31:00.799997Z",
     "shell.execute_reply": "2024-03-14T15:31:00.799087Z",
     "shell.execute_reply.started": "2024-03-14T15:31:00.750990Z"
    },
    "id": "d9600b67-79d4-4f85-aba2-9fe81fa29f49",
    "outputId": "571e0f5c-c964-4321-daf2-a116a5fb21ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- YandexGPT - сервис Yandex Cloud для генерации текстового контента на стадии preview.\n",
      "- Предназначен для создания описаний, статей, информационных рассылок.\n",
      "- Качество ответа зависит от инструкций.\n",
      "- Функциональность расширяется через Библиотеку Яндекс GPT и API.\n",
      "- Два режима работы: синхронный для чат-ботов и асинхронный для качественного ответа.\n",
      "- Максимальное количество токенов: 8 000\n"
     ]
    }
   ],
   "source": [
    "print(result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f91a8eb-daa5-4191-ace4-01765801db3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:31:06.784212Z",
     "iopub.status.busy": "2024-03-14T15:31:06.783446Z",
     "iopub.status.idle": "2024-03-14T15:31:06.811113Z",
     "shell.execute_reply": "2024-03-14T15:31:06.810314Z",
     "shell.execute_reply.started": "2024-03-14T15:31:06.784169Z"
    },
    "id": "5f91a8eb-daa5-4191-ace4-01765801db3e",
    "outputId": "4aaf18c0-e6b6-4726-881d-69b52bd21f20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- YandexGPT API - сервис от Yandex Cloud, предоставляющий доступ к генеративным нейросетям.\n",
      "- YandexGPT API находится на стадии preview и входит в состав сервиса Yandex Foundation Models, объединяющего несколько больших нейросетей.\n",
      "- Сервис Yandex Foundation Models предназначен для использования в бизнес-задачах.\n",
      "\n",
      "- YandexGPT - сервис Yandex Cloud для доступа к генеративным нейросетевым моделям.\n",
      "- Находится на стадии preview в составе Yandex Foundation Models.\n",
      "- Предназначен для использования в бизнесе.\n",
      "- Нейросеть решает задачи создания текстового контента, включая описание товаров, статей, новостей и информационных рассылок.\n",
      "- Качество ответа зависит от точности инструкции.\n",
      "- Функциональность и возможности сервиса постоянно расширяются.\n",
      "- Примеры инструкций и запросов доступны в Библиотеке Промтов YandexGPT.\n",
      "\n",
      "- YandexGPT представляет собой сервис Yandex Cloud, предназначенный для генерации текстового контента.\n",
      "- Сервис находится на стадии preview и предназначен для использования в бизнес-целях.\n",
      "- Он решает задачи создания описаний товаров, статей и информационных рассылок, качество ответа зависит от инструкции.\n",
      " - Функциональность сервиса расширяется, примеры инструкций и запросов можно найти в Библиотеке Яндекс GPT.\n",
      "- В YandexGPT API доступны два режима работы: синхронный и асинхронный.\n",
      "- Синхронный режим подходит для поддержания диалога чат-ботов, а асинхронный - для более качественного и дешевого ответа, но требует больше времени.\n",
      "- Оба режима не могут обрабатывать бесконечное количество информации, максимальное количество токенов составляет 8 000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join(result[\"intermediate_steps\"][:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8a8398-a43c-4f14-933c-c0743ae6ec40",
   "metadata": {
    "id": "0d8a8398-a43c-4f14-933c-c0743ae6ec40"
   },
   "source": [
    "## Разбивка и суммирование в единую цепочку\n",
    "Для удобства мы можем объединить как разбиение текста нашего длинного документа, так и подведение итогов в одном документе.`AnalyzeDocumentsChain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ddd522e-30dc-4f6a-b993-c4f97e656c4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:39:32.151910Z",
     "iopub.status.busy": "2024-03-14T15:39:32.151109Z",
     "iopub.status.idle": "2024-03-14T15:39:40.760059Z",
     "shell.execute_reply": "2024-03-14T15:39:40.759155Z",
     "shell.execute_reply.started": "2024-03-14T15:39:32.151856Z"
    },
    "id": "0ddd522e-30dc-4f6a-b993-c4f97e656c4f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import AnalyzeDocumentChain\n",
    "\n",
    "summarize_document_chain = AnalyzeDocumentChain(\n",
    "    combine_docs_chain=chain, text_splitter=text_splitter\n",
    ")\n",
    "summary=summarize_document_chain.invoke(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d8df14d0-d548-4a5d-b00a-f4cfd64f1076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:38:52.420895Z",
     "iopub.status.busy": "2024-03-14T15:38:52.420143Z",
     "iopub.status.idle": "2024-03-14T15:38:52.487303Z",
     "shell.execute_reply": "2024-03-14T15:38:52.486536Z",
     "shell.execute_reply.started": "2024-03-14T15:38:52.420862Z"
    },
    "id": "d8df14d0-d548-4a5d-b00a-f4cfd64f1076",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_document': 'О сервисе YandexGPT API | Yandex Cloud - ДокументацияПоискСвязаться с намиПодключитьсяСервисыРешенияПочему Yandex CloudРесурсыТарифыДокументацияБлогРоссияПроект Яндекса© 2024 ООО «Яндекс.Облако»YandexGPT APIНачало работыПошаговые инструкцииПрактические руководстваКонцепцииСправочники APIБиблиотека промтовУправление доступомРешение проблемПравила тарификацииИстория измененийКонцепцииО сервисе YandexGPT APIО сервисе YandexGPT APIСтатья созданаYandex CloudОбновлена 29 января 2024 г.YandexGPT находится на стадии Preview и является частью сервиса Yandex Foundation Models.\\nCервис Yandex Foundation Models объединит в себе несколько больших генеративных нейросетей и поможет вам использовать их возможности для своих бизнес-задач.\\nНейросеть YandexGPT умеет решать различные задачи, связанные с созданием текстового контента. YandexGPT API может генерировать описание товаров, статьи, новости, информационные рассылки, посты для блога и многое другое. Качество ответа нейросети напрямую зависит от точности переданной инструкции: чем точнее вы опишете свой запрос, тем выше вероятность получить ожидаемый результат.\\nСейчас сервис активно развивается, его функциональность постоянно дополняется и совершенствуется. С помощью YandexGPT API можно решать задачи, связанные с созданием текстового контента: описание товаров, статьи, новости, информационные рассылки, посты для блога и многое другое. Примеры инструкций и запросов собраны в Библиотеке промтов YandexGPT API.\\nРежимы работы YandexGPT APIРежимы работы YandexGPT API\\nВ YandexGPT API можно отправлять запросы в синхронном и асинхронном режимах. В синхронном режиме сервис обработает ваш запрос и ответит на него сразу после получения. Этот режим походит, если вам нужно поддерживать диалог чат-бота. В асинхронном режиме сервис получит запрос и сразу же вернет его идентификатор, по которому вы сможете получить ответ. Генерация текста займет больше времени, но ответ будет качественнее и дешевле. Асинхронный режим подойдет, если ваши задачи не требуют срочного ответа.\\nОба режима работы пока не могут обрабатывать бесконечные объемы информации. На текущий момент максимальное суммарное количество токенов, которое может содержаться в запросе пользователя и ответе модели, составляет 8000. Подробнее об ограничениях сервиса см. в разделе Квоты и лимиты в YandexGPT API.\\nВ консоли управления доступен YandexGPT Playground: вы можете протестировать модель YandexGPT, отправляя ей синхронные запросы двух типов:\\n\\n\\nПромт-режим, в котором вы отправляете в модель подготовленный промт — инструкцию и запрос — и получаете ответ. При этом каждый новый вопрос модель воспринимает как самостоятельное задание и не сохраняет контекст предыдущего обращения.\\n\\n\\nВ режиме Чат вы переписываетесь с моделью, уточняя задания и дополняя предыдущие реплики. Контекст общения передается в каждом сообщении и сохраняется в течение сессии, пока вы явно не начнете новую сессию.\\n\\n\\nИ промт-сообщения, и сообщения в режиме чат вы можете отправлять с помощью обновленного API.\\nБыла ли статья полезна?ДаНетРоссияПроект Яндекса© 2024 ООО «Яндекс.Облако»\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " 'intermediate_steps': ['- YandexGPT API - сервис от Yandex Cloud, предоставляющий доступ к генеративным нейросетям.\\n- YandexGPT API находится на стадии preview и входит в состав сервиса Yandex Foundation Models, объединяющего несколько больших нейросетей.\\n- Сервис Yandex Foundation Models предназначен для использования в бизнес-задачах.',\n",
       "  '- YandexGPT - сервис Yandex Cloud для доступа к генеративным нейросетевым моделям.\\n- Находится на стадии preview в составе Yandex Foundation Models.\\n- Предназначен для использования в бизнесе.\\n- Нейросеть решает задачи создания текстового контента, включая описание товаров, статей, новостей и информационных рассылок.\\n- Качество ответа зависит от точности инструкции.\\n- Функциональность и возможности сервиса постоянно расширяются.\\n- Примеры инструкций и запросов доступны в Библиотеке Промтов YandexGPT.',\n",
       "  '- YandexGPT представляет собой сервис Yandex Cloud, предназначенный для генерации текстового контента.\\n- Сервис находится на стадии preview и предназначен для использования в бизнес-целях.\\n- Он решает задачи создания описаний товаров, статей и информационных рассылок, качество ответа зависит от инструкции.\\n - Функциональность сервиса расширяется, примеры инструкций и запросов можно найти в Библиотеке Яндекс GPT.\\n- В YandexGPT API доступны два режима работы: синхронный и асинхронный.\\n- Синхронный режим подходит для поддержания диалога чат-ботов, а асинхронный - для более качественного и дешевого ответа, но требует больше времени.\\n- Оба режима не могут обрабатывать бесконечное количество информации, максимальное количество токенов составляет 8 000',\n",
       "  '- YandexGPT - сервис Yandex Cloud для генерации текстового контента на стадии preview.\\n- Предназначен для создания описаний, статей, информационных рассылок.\\n- Качество ответа зависит от инструкций.\\n- Функциональность расширяется через Библиотеку Яндекс GPT и API.\\n- Два режима работы: синхронный для чат-ботов и асинхронный для качественного ответа.\\n- Максимальное количество токенов: 8 000'],\n",
       " 'output_text': '- YandexGPT - сервис Yandex Cloud для генерации текстового контента на стадии preview.\\n- Предназначен для создания описаний, статей, информационных рассылок.\\n- Качество ответа зависит от инструкций.\\n- Функциональность расширяется через Библиотеку Яндекс GPT и API.\\n- Два режима работы: синхронный для чат-ботов и асинхронный для качественного ответа.\\n- Максимальное количество токенов: 8 000'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae35712f-49ad-44e3-bfc9-4582ea684e0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:39:10.281653Z",
     "iopub.status.busy": "2024-03-14T15:39:10.280763Z",
     "iopub.status.idle": "2024-03-14T15:39:10.292854Z",
     "shell.execute_reply": "2024-03-14T15:39:10.291982Z",
     "shell.execute_reply.started": "2024-03-14T15:39:10.281604Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "О сервисе YandexGPT API | Yandex Cloud - ДокументацияПоискСвязаться с намиПодключитьсяСервисыРешенияПочему Yandex CloudРесурсыТарифыДокументацияБлогРоссияПроект Яндекса© 2024 ООО «Яндекс.Облако»YandexGPT APIНачало работыПошаговые инструкцииПрактические руководстваКонцепцииСправочники APIБиблиотека промтовУправление доступомРешение проблемПравила тарификацииИстория измененийКонцепцииО сервисе YandexGPT APIО сервисе YandexGPT APIСтатья созданаYandex CloudОбновлена 29 января 2024 г.YandexGPT находится на стадии Preview и является частью сервиса Yandex Foundation Models.\n",
      "Cервис Yandex Foundation Models объединит в себе несколько больших генеративных нейросетей и поможет вам использовать их возможности для своих бизнес-задач.\n",
      "Нейросеть YandexGPT умеет решать различные задачи, связанные с созданием текстового контента. YandexGPT API может генерировать описание товаров, статьи, новости, информационные рассылки, посты для блога и многое другое. Качество ответа нейросети напрямую зависит от точности переданной инструкции: чем точнее вы опишете свой запрос, тем выше вероятность получить ожидаемый результат.\n",
      "Сейчас сервис активно развивается, его функциональность постоянно дополняется и совершенствуется. С помощью YandexGPT API можно решать задачи, связанные с созданием текстового контента: описание товаров, статьи, новости, информационные рассылки, посты для блога и многое другое. Примеры инструкций и запросов собраны в Библиотеке промтов YandexGPT API.\n",
      "Режимы работы YandexGPT APIРежимы работы YandexGPT API\n",
      "В YandexGPT API можно отправлять запросы в синхронном и асинхронном режимах. В синхронном режиме сервис обработает ваш запрос и ответит на него сразу после получения. Этот режим походит, если вам нужно поддерживать диалог чат-бота. В асинхронном режиме сервис получит запрос и сразу же вернет его идентификатор, по которому вы сможете получить ответ. Генерация текста займет больше времени, но ответ будет качественнее и дешевле. Асинхронный режим подойдет, если ваши задачи не требуют срочного ответа.\n",
      "Оба режима работы пока не могут обрабатывать бесконечные объемы информации. На текущий момент максимальное суммарное количество токенов, которое может содержаться в запросе пользователя и ответе модели, составляет 8000. Подробнее об ограничениях сервиса см. в разделе Квоты и лимиты в YandexGPT API.\n",
      "В консоли управления доступен YandexGPT Playground: вы можете протестировать модель YandexGPT, отправляя ей синхронные запросы двух типов:\n",
      "\n",
      "\n",
      "Промт-режим, в котором вы отправляете в модель подготовленный промт — инструкцию и запрос — и получаете ответ. При этом каждый новый вопрос модель воспринимает как самостоятельное задание и не сохраняет контекст предыдущего обращения.\n",
      "\n",
      "\n",
      "В режиме Чат вы переписываетесь с моделью, уточняя задания и дополняя предыдущие реплики. Контекст общения передается в каждом сообщении и сохраняется в течение сессии, пока вы явно не начнете новую сессию.\n",
      "\n",
      "\n",
      "И промт-сообщения, и сообщения в режиме чат вы можете отправлять с помощью обновленного API.\n",
      "Была ли статья полезна?ДаНетРоссияПроект Яндекса© 2024 ООО «Яндекс.Облако»\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['- YandexGPT API - сервис от Yandex Cloud, предоставляющий доступ к генеративным нейросетям.\\n- YandexGPT API находится на стадии preview и входит в состав сервиса Yandex Foundation Models, объединяющего несколько больших нейросетей.\\n- Сервис Yandex Foundation Models предназначен для использования в бизнес-задачах.', '- YandexGPT - сервис Yandex Cloud для доступа к генеративным нейросетевым моделям.\\n- Находится на стадии preview в составе Yandex Foundation Models.\\n- Предназначен для использования в бизнесе.\\n- Нейросеть решает задачи создания текстового контента, включая описание товаров, статей, новостей и информационных рассылок.\\n- Качество ответа зависит от точности инструкции.\\n- Функциональность и возможности сервиса постоянно расширяются.\\n- Примеры инструкций и запросов доступны в Библиотеке Промтов YandexGPT.', '- YandexGPT представляет собой сервис Yandex Cloud, предназначенный для генерации текстового контента.\\n- Сервис находится на стадии preview и предназначен для использования в бизнес-целях.\\n- Он решает задачи создания описаний товаров, статей и информационных рассылок, качество ответа зависит от инструкции.\\n - Функциональность сервиса расширяется, примеры инструкций и запросов можно найти в Библиотеке Яндекс GPT.\\n- В YandexGPT API доступны два режима работы: синхронный и асинхронный.\\n- Синхронный режим подходит для поддержания диалога чат-ботов, а асинхронный - для более качественного и дешевого ответа, но требует больше времени.\\n- Оба режима не могут обрабатывать бесконечное количество информации, максимальное количество токенов составляет 8 000', '- YandexGPT - сервис Yandex Cloud для генерации текстового контента на стадии preview.\\n- Предназначен для создания описаний, статей, информационных рассылок.\\n- Качество ответа зависит от инструкций.\\n- Функциональность расширяется через Библиотеку Яндекс GPT и API.\\n- Два режима работы: синхронный для чат-ботов и асинхронный для качественного ответа.\\n- Максимальное количество токенов: 8 000']\n"
     ]
    }
   ],
   "source": [
    "print(summary.get('input_document'))\n",
    "print(summary.get('intermediate_steps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60010c-7d1c-4513-9c18-f408c2f70f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4448adb2-3267-473b-8f9d-65e2ec017280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
